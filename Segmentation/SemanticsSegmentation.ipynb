{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f6d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227c0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "train_size = 0.9\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-6\n",
    "batch_size = 32\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b14583bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-12 16:29:28--  https://dl.dropboxusercontent.com/s/k88qukc20ljnbuo/PH2Dataset.rar\n",
      "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.66.15, 2620:100:6021:15::a27d:410f\n",
      "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.66.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 403 Forbidden\n",
      "2025-05-12 16:29:35 ERROR 403: Forbidden.\n",
      "\n",
      "\n",
      "UNRAR 7.00 freeware      Copyright (c) 1993-2024 Alexander Roshal\n",
      "\n",
      "PH2Dataset.rar is not RAR archive\n",
      "No files to extract\n"
     ]
    }
   ],
   "source": [
    "!wget -O PH2Dataset.rar \"https://dl.dropboxusercontent.com/s/k88qukc20ljnbuo/PH2Dataset.rar\"\n",
    "!unrar x -Y PH2Dataset.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c16ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images and 0 masks.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 1 is not equal to len(dims) = 4",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     23\u001b[39m     test_dataset = (images[test_ind, :, :, :], masks[test_ind, :, :, :])\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_dataset, test_dataset\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m train_dataset, test_dataset = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(train_part, root)\u001b[39m\n\u001b[32m     11\u001b[39m size = (\u001b[32m256\u001b[39m, \u001b[32m256\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m images and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(masks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m masks.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m images = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconstant\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manti_aliasing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m masks = torch.FloatTensor(np.array([resize(mask, size, mode=\u001b[33m'\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m'\u001b[39m, anti_aliasing=\u001b[38;5;28;01mFalse\u001b[39;00m) > \u001b[32m0.5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m masks])).unsqueeze(\u001b[32m1\u001b[39m)\n\u001b[32m     17\u001b[39m indices = np.random.permutation(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(images)))\n",
      "\u001b[31mRuntimeError\u001b[39m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 1 is not equal to len(dims) = 4"
     ]
    }
   ],
   "source": [
    "def load_dataset(train_part, root='PH2Dataset'):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.join(root, 'PH2 Dataset images')):\n",
    "        if root.endswith('_Dermoscopic_Image'):\n",
    "            images.append(imread(os.path.join(root, files[0])))\n",
    "        if root.endswith('_lesion'):\n",
    "            masks.append(imread(os.path.join(root, files[0])))\n",
    "\n",
    "    size = (256, 256)\n",
    "    print(f\"Found {len(images)} images and {len(masks)} masks.\")\n",
    "\n",
    "    images = torch.permute(torch.FloatTensor(np.array([resize(image, size, mode='constant', anti_aliasing=True,) for image in images])), (0, 3, 1, 2))\n",
    "    masks = torch.FloatTensor(np.array([resize(mask, size, mode='constant', anti_aliasing=False) > 0.5 for mask in masks])).unsqueeze(1)\n",
    "\n",
    "    indices = np.random.permutation(range(len(images)))\n",
    "    train_part = int(train_part * len(images))\n",
    "    train_ind = indices[:train_part]\n",
    "    test_ind = indices[train_part:]\n",
    "\n",
    "    train_dataset = (images[train_ind, :, :, :], masks[train_ind, :, :, :])\n",
    "    test_dataset = (images[test_ind, :, :, :], masks[test_ind, :, :, :])\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "train_dataset, test_dataset = load_dataset(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c8e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotn(n, data, only_mask=False):\n",
    "    images, masks = data[0], data[1]\n",
    "    fig, ax = plt.subplots(1, n)\n",
    "    fig1, ax1 = plt.subplots(1, n)\n",
    "    for i, (img, mask) in enumerate(zip(images, masks)):\n",
    "        if i==n:\n",
    "            break\n",
    "        if not only_mask:\n",
    "            ax[i].imshow(torch.permute(img, (1, 2, 0)))\n",
    "        else:\n",
    "            ax[i].imshow(mask[0])  \n",
    "        ax1[i].imshow(mask[0])\n",
    "        ax[i].axis('off')\n",
    "        ax1[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plotn(5, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(list(zip(train_dataset[0], train_dataset[1])), batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(list(zip(test_dataset[0], test_dataset[1])), batch_size=1, shuffle=False)\n",
    "dataloaders = (train_dataloader, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-x-CTmFw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
