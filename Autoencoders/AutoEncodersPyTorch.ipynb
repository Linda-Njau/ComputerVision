{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f2964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c02a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09997419",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "train_size = 0.9\n",
    "lr = 1e-3\n",
    "eps = 1e-8\n",
    "batch_size = 256\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4867108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist(train_part, transform=None):\n",
    "    dataset = torchvision.datasets.MNIST('.', download=True, transform=transform)\n",
    "    train_part = int(train_part * len(dataset))\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_part, len(dataset) - train_part])\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f079801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset, test_dataset = mnist(train_size, transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "dataloaders = (train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0496b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotn(n, data, noisy=False, super_res=None):\n",
    "    fig, ax = plt.subplots(1, n)\n",
    "    for i, z in enumerate(data):\n",
    "        if i == n:\n",
    "            break\n",
    "        preprocess = z[0].reshape(1,28,28,) if z[0].shape[1] == 28 else z[0].reshape(1, 14, 14) if z[0].shape[1] == 14 else z[0]\n",
    "        if  super_res is not None:\n",
    "            _transform = transform.Resize((int(preprocess.shape[1] / super_res), int(preprocess.shape[2] / super_res)))\n",
    "        if noisy:\n",
    "            shapes = list(preprocess.shape)\n",
    "            preprocess += noisify(shapes)\n",
    "        ax[i].imshow(preprocess[0])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f7984dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisify(shapes):\n",
    "    return np.random.normal(loc=0.5, scale=0.3, size=shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a34ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotn(5, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0348246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3,3), padding='same')\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=(3,3), padding='same')\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.conv3 = nn.Conv2d(8, 8, kernel_size=(3,3), padding='same')\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=(2,2), padding=(1,1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden1 = self.maxpool1(self.relu(self.conv1(input)))\n",
    "        hidden2 = self.maxpool2(self.relu(self.conv2(hidden1)))\n",
    "        encoded = self.maxpool3(self.relu(self.conv3(hidden2)))\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f33e0f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(8, 8, kernel_size=(3,3), padding='same')\n",
    "        self.upsample1 = nn.Upsample(scale_factor=(2,2))\n",
    "        self.conv2 = nn.Conv2d(8,8, kernel_size=(3,3), padding='same')\n",
    "        self.upsample2 = nn.Upsample(scale_factor=(2,2))\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=(3, 3))\n",
    "        self.upsample3 = nn.Upsample(scale_factor=(2, 2))\n",
    "        self.conv4 = nn.Conv2d(16, 1, kernel_size=(3, 3), padding='same')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        hidden1 = self.upsample1(self.relu(self.conv1(input)))\n",
    "        hidden2 = self.upsample2(self.relu(self.conv2(hidden1)))\n",
    "        hidden3 = self.upsample3(self.relu(self.conv3(hidden2)))\n",
    "        decoded = self.sigmoid(self.conv4(hidden3))\n",
    "        return decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d901025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, super_resolution=False):\n",
    "        super().__init__()\n",
    "        if not super_resolution:\n",
    "            self.encoder = Encoder()\n",
    "        else:\n",
    "            self.encoder = SuperResolutionEncoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        encoded = self.encoder(input)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e500bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, eps=eps)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1c17ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloaders, model, loss_fn, optimizer, epochs, device, noisy=None, super_res=None):\n",
    "    tqdm_iter = tqdm(range(epochs))\n",
    "    train_dataloader, test_dataloader = dataloaders[0], dataloaders[1]\n",
    "\n",
    "    for epoch in tqdm_iter:\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        imgs, labels = batch\n",
    "        shapes = list(imgs.shape)\n",
    "\n",
    "        if super_res is not None:\n",
    "            shapes[2], shapes[3] = int(shapes[2] / super_res), int(shapes[3] / super_res)\n",
    "            _transform = transforms.Resize((shapes[2], shapes[3]))\n",
    "            img_transformed = _transform(imgs)\n",
    "            img_transformed = img_transformed.to(device)\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if noisy is not None:\n",
    "            noisy_tensor = noisy[0]\n",
    "        else:\n",
    "            noisy_tensor = torch.zeros(tuple(shapes)).to(device)\n",
    "        if super_res is None:\n",
    "            imgs_noisy = imgs + noisy_tensor\n",
    "        else:\n",
    "            imgs_noisy = img_transformed + noisy_tensor\n",
    "        \n",
    "        imgs_noisy = torch.clamp(imgs_noisy, 0., 1.)\n",
    "\n",
    "        preds = model(imgs_noisy)\n",
    "        loss = loss_fn(preds, imgs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            imgs, labels = batch\n",
    "            shapes = list(imgs.shape)\n",
    "\n",
    "            if super_res is not None:\n",
    "                shapes[2], shapes[3] = int(shapes[2] / super_res), int(shapes[3] / super_res)\n",
    "                _transform = transforms.Resize((shapes[2], shapes[3]))\n",
    "                img_transformed = transform(imgs)\n",
    "                imgs_transformed = img_transformed.to(device)\n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if noisy is not None:\n",
    "                test_noisy_tensor = noisy[1]\n",
    "            else:\n",
    "                test_noisy_tensor = torch.zeros(tuple(shapes)).to(device)\n",
    "            if super_res is None:\n",
    "                imgs_noisy = imgs + test_noisy_tensor\n",
    "            else:\n",
    "                imgs_noisy = imgs_transformed + test_noisy_tensor\n",
    "\n",
    "            imgs_noisy = torch.clamp(imgs_noisy, 0., 1.)\n",
    "\n",
    "            preds = model(imgs_noisy)\n",
    "            loss = loss_fn(preds, imgs)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    test_loss /= len(test_dataloader)\n",
    "\n",
    "    tqdm_dct = {'train loss:': train_loss, 'test_loss:': test_loss}\n",
    "    tqdm_iter.set_postfix(tqdm_dct, refresh=True)\n",
    "    tqdm_iter.refresh()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366ccb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 3930.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(dataloaders, model, loss_fn, optimizer, epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-x-CTmFw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
